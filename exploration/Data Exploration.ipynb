{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "# Load data from pre-saved pickle files for faster \n",
    "general = pd.read_csv('data/init_general.csv')\n",
    "customers = pd.read_csv('data/init_customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891221, 367)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  910215        -1         NaN       NaN          NaN          NaN   \n",
       "1  910220        -1         9.0       0.0          NaN          NaN   \n",
       "2  910225        -1         9.0      17.0          NaN          NaN   \n",
       "3  910226         2         1.0      13.0          NaN          NaN   \n",
       "4  910241        -1         1.0      20.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   NaN                  NaN  ...   \n",
       "1          NaN          NaN                  21.0                 11.0  ...   \n",
       "2          NaN          NaN                  17.0                 10.0  ...   \n",
       "3          NaN          NaN                  13.0                  1.0  ...   \n",
       "4          NaN          NaN                  14.0                  3.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1       8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2       9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3       7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4       3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB     TYPE  \n",
       "0         3         1                    2  general  \n",
       "1         5         2                    1  general  \n",
       "2         5         2                    3  general  \n",
       "3         3         2                    4  general  \n",
       "4         4         1                    3  general  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{general.shape}')\n",
    "general.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191652, 370)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9626</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9628</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143872</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143873</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COSMETIC</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143874</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0    9626         2         1.0      10.0          NaN          NaN   \n",
       "1    9628        -1         9.0      11.0          NaN          NaN   \n",
       "2  143872        -1         1.0       6.0          NaN          NaN   \n",
       "3  143873         1         1.0       8.0          NaN          NaN   \n",
       "4  143874        -1         1.0      20.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                  10.0                  1.0  ...   \n",
       "1          NaN          NaN                   NaN                  NaN  ...   \n",
       "2          NaN          NaN                   0.0                  1.0  ...   \n",
       "3          NaN          NaN                   8.0                  0.0  ...   \n",
       "4          NaN          NaN                  14.0                  7.0  ...   \n",
       "\n",
       "   W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP      PRODUCT_GROUP  \\\n",
       "0             6.0             9.0       7.0         3  COSMETIC_AND_FOOD   \n",
       "1             0.0             9.0       NaN         3               FOOD   \n",
       "2             6.0             9.0       2.0         3  COSMETIC_AND_FOOD   \n",
       "3             NaN             9.0       7.0         1           COSMETIC   \n",
       "4             2.0             9.0       3.0         1               FOOD   \n",
       "\n",
       "   CUSTOMER_GROUP  ONLINE_PURCHASE ANREDE_KZ ALTERSKATEGORIE_GROB      TYPE  \n",
       "0     MULTI_BUYER                0         1                    4  customer  \n",
       "1    SINGLE_BUYER                0         1                    4  customer  \n",
       "2     MULTI_BUYER                0         2                    4  customer  \n",
       "3     MULTI_BUYER                0         1                    4  customer  \n",
       "4     MULTI_BUYER                0         1                    3  customer  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{customers.shape}')\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra columns in customers\n",
    "set(customers.columns) - set(general.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_GROUP</th>\n",
       "      <th>ONLINE_PURCHASE</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINGLE_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMETIC_AND_FOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMETIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTI_BUYER</td>\n",
       "      <td>0</td>\n",
       "      <td>FOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CUSTOMER_GROUP  ONLINE_PURCHASE      PRODUCT_GROUP\n",
       "0    MULTI_BUYER                0  COSMETIC_AND_FOOD\n",
       "1   SINGLE_BUYER                0               FOOD\n",
       "2    MULTI_BUYER                0  COSMETIC_AND_FOOD\n",
       "3    MULTI_BUYER                0           COSMETIC\n",
       "4    MULTI_BUYER                0               FOOD"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate the three extra columns: ['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP']\n",
    "customers[['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the overall population is made up of both `general` and `customers`, for general preprocessing techniques and exploration, it's would be more generalized to work on the merge data of common features between the two sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([general, customers.drop(columns=['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1082873, 367)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  910215        -1         NaN       NaN          NaN          NaN   \n",
       "1  910220        -1         9.0       0.0          NaN          NaN   \n",
       "2  910225        -1         9.0      17.0          NaN          NaN   \n",
       "3  910226         2         1.0      13.0          NaN          NaN   \n",
       "4  910241        -1         1.0      20.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   NaN                  NaN  ...   \n",
       "1          NaN          NaN                  21.0                 11.0  ...   \n",
       "2          NaN          NaN                  17.0                 10.0  ...   \n",
       "3          NaN          NaN                  13.0                  1.0  ...   \n",
       "4          NaN          NaN                  14.0                  3.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1       8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2       9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3       7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4       3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB     TYPE  \n",
       "0         3         1                    2  general  \n",
       "1         5         2                    1  general  \n",
       "2         5         2                    3  general  \n",
       "3         3         2                    4  general  \n",
       "4         4         1                    3  general  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMEO_DEUG_2015\n",
      "[nan  8.  4.  2.  6.  1.  9.  5.  7.  3.]\n",
      "CAMEO_INTL_2015\n",
      "[nan 51. 24. 12. 43. 54. 22. 14. 13. 15. 33. 41. 34. 55. 25. 23. 31. 52.\n",
      " 35. 45. 44. 32.]\n",
      "CAMEO_DEU_2015\n"
     ]
    }
   ],
   "source": [
    "# fix the mixed datatype message\n",
    "\n",
    "# check which columns having mixed datatype\n",
    "COLUMNS_WITH_MIXED_TYPES = ['CAMEO_DEUG_2015', 'CAMEO_INTL_2015', 'CAMEO_DEU_2015']\n",
    "\n",
    "# replace the outline 'X' and 'XX' value with nan\n",
    "def format_mixed_types(df, cols_mixed_types=COLUMNS_WITH_MIXED_TYPES):\n",
    "    '''This function is created for formating improper\n",
    "    values in columns CAMEO_DEUG_2015 and CAMEO_INTL_2015.\n",
    "    Args:\n",
    "    df: demographics dataframe\n",
    "    returns: transformed dataframe\n",
    "    '''\n",
    "\n",
    "    if set(cols_mixed_types).issubset(df.columns):\n",
    "        for col in cols_mixed_types:\n",
    "            print(col)\n",
    "            df[col] = df[col].replace({'X': np.nan, 'XX': np.nan})\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            print(df[col].unique())\n",
    "\n",
    "    return df\n",
    "\n",
    "df = format_mixed_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop 0 duplicated rows, Number of rows after drop: 1082873\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate\n",
    "(nrow, ncol) = df.shape\n",
    "df.drop_duplicates(keep='last', inplace=True)\n",
    "print(f'Drop {df.shape[0]-nrow} duplicated rows, Number of rows after drop: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 attributes with more than 30% values missing, /n  1.6% of total attributes\n",
      "Cols to drop: ['ALTER_KIND4', 'ALTER_KIND3', 'ALTER_KIND2', 'ALTER_KIND1', 'EXTSEL992', 'KK_KUNDENTYP']\n"
     ]
    }
   ],
   "source": [
    "# missing rates of columns\n",
    "missing = df.isnull().sum().sort_values(ascending=False) / nrow\n",
    "cols_missing_30pect = list(missing[missing>0.3].index)\n",
    "print(f'There are {len(cols_missing_30pect)} attributes with more than 30% values missing, /n'\n",
    "      f'  {round(len(cols_missing_30pect)/ncol,3)*100}% of total attributes')\n",
    "print(f'Cols to drop: {cols_missing_30pect}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LNR has 100.0% values are unique\n",
      "D19_BANKEN_LOKAL has 98.0% values belongs to categoy 0\n",
      "D19_BANKEN_OFFLINE_DATUM has 97.0% values belongs to categoy 10\n",
      "D19_DIGIT_SERV has 96.0% values belongs to categoy 0\n",
      "D19_GARTEN has 95.0% values belongs to categoy 0\n",
      "D19_TELKO_ANZ_12 has 96.0% values belongs to categoy 0\n",
      "D19_TELKO_ONLINE_DATUM has 99.0% values belongs to categoy 10\n",
      "D19_TIERARTIKEL has 96.0% values belongs to categoy 0\n",
      "D19_VERSI_OFFLINE_DATUM has 96.0% values belongs to categoy 10\n",
      "D19_VERSI_ONLINE_DATUM has 99.0% values belongs to categoy 10\n",
      "There are 10 columns with identifier or columns with one value with more than 95% of total population\n"
     ]
    }
   ],
   "source": [
    "# find columns with identifier or columns with one value with more than 95% of total population\n",
    "\n",
    "def identifier_to_drop(df):\n",
    "    nrow = df.shape[0]\n",
    "    cols_to_drop = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        # check if column has more than 95% of values are uniques\n",
    "        nunique_rate = df[col].nunique() / nrow\n",
    "        if nunique_rate > 0.95:\n",
    "            cols_to_drop.append(col)\n",
    "            print(f'{col} has {round(nunique_rate, 2) * 100}% values are unique')\n",
    "\n",
    "        # check if column has more than 95% of values belongs to only 1 categories\n",
    "        mode_count = df[col].value_counts().values[0]\n",
    "        mode_freq = mode_count / nrow\n",
    "        if mode_freq > 0.95:\n",
    "            cols_to_drop.append(col)\n",
    "            print(f'{col} has {round(mode_freq, 2) * 100}% values belongs to categoy {df[col].value_counts().index[0]}')\n",
    "\n",
    "    return cols_to_drop\n",
    "\n",
    "drop_identifier_cols = identifier_to_drop(df)\n",
    "print(f'There are {len(drop_identifier_cols)} columns with identifier or columns with one value with more than '\n",
    "      f'95% of total population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22 columns that highly correlated with each others\n"
     ]
    }
   ],
   "source": [
    "# find columns that highly correlated\n",
    "\n",
    "def corr_to_drop(df):\n",
    "    # Create correlation matrix for just Features to determine different models to test\n",
    "    corr_matrix = df.corr().abs().round(2)\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.90\n",
    "    cols_to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "    return cols_to_drop\n",
    "\n",
    "drop_high_corr_cols = corr_to_drop(df)\n",
    "print(f'There are {len(drop_high_corr_cols)} columns that highly correlated with each others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 columns will be dropped from the dataset: ['ALTER_KIND2', 'KBA13_KMH_250', 'KBA13_HALTER_66', 'D19_DIGIT_SERV', 'CAMEO_INTL_2015', 'KBA13_HERST_SONST', 'LP_LEBENSPHASE_GROB', 'LP_FAMILIE_GROB', 'D19_VERSAND_ANZ_24', 'LNR', 'D19_TELKO_ANZ_12', 'PLZ8_HHZ', 'D19_TELKO_ONLINE_DATUM', 'D19_TIERARTIKEL', 'PLZ8_GBZ', 'ORTSGR_KLS9', 'PLZ8_ANTG3', 'KK_KUNDENTYP', 'LP_LEBENSPHASE_FEIN', 'D19_VERSI_OFFLINE_DATUM', 'D19_VERSAND_ANZ_12', 'D19_VERSAND_ONLINE_QUOTE_12', 'EXTSEL992', 'D19_GESAMT_ANZ_24', 'LP_STATUS_GROB', 'ANZ_STATISTISCHE_HAUSHALTE', 'D19_BANKEN_OFFLINE_DATUM', 'KBA05_KRSHERST3', 'D19_VERSAND_ONLINE_DATUM', 'D19_BANKEN_LOKAL', 'D19_GARTEN', 'PLZ8_ANTG1', 'ALTER_KIND1', 'CJT_TYP_2', 'PLZ8_BAUMAX', 'D19_VERSI_ONLINE_DATUM', 'ALTER_KIND3', 'ALTER_KIND4']\n",
      "Dropped -38 columns, Number of columns after drop: 329\n"
     ]
    }
   ],
   "source": [
    "# append to drop cols\n",
    "drop_cols = list(set(cols_missing_30pect + drop_high_corr_cols + drop_identifier_cols))\n",
    "print(\"{} columns will be dropped from the dataset: {}\".format(len(drop_cols), drop_cols))\n",
    "\n",
    "df.drop(columns=drop_cols, inplace=True)\n",
    "print(f'Dropped {df.shape[1] - ncol} columns, Number of columns after drop: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 157147 rows with more than 84 attributes missing\n"
     ]
    }
   ],
   "source": [
    "# missing rows\n",
    "df_null_rows = df.isnull().sum(axis=1)\n",
    "drop_missing_rows = list(df_null_rows[df_null_rows > 84].index)\n",
    "print(f'There are {len(drop_missing_rows)} rows with more than 84 attributes missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 218784 rows, Number of rows after drop: 864089\n"
     ]
    }
   ],
   "source": [
    "# drop missing rows\n",
    "nrow = df.shape[0]\n",
    "df.drop(labels=drop_missing_rows, axis=0, inplace=True)\n",
    "print(f'Dropped {nrow - df.shape[0]} rows, Number of rows after drop: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature transformation\n",
    "# transform datetime variable into Year and Month, + drop variables with too many values\n",
    "def clean_categorical(df, cols_drop = []):\n",
    "    '''This function deals designated columns and imputes missing data.\n",
    "    Args:\n",
    "    df: demographic dataframe\n",
    "    returns: none\n",
    "    '''\n",
    "#     print('--CLEAN CATEGORICAL VARIABLES--')\n",
    "    categorical_cols = list(df.select_dtypes(['object']).columns)\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        # Convert columns 'EINGEFUEGT_AM'\n",
    "        if col == 'EINGEFUEGT_AM':\n",
    "            df['EINGEFUEGT_AM_YEAR'] = df['EINGEFUEGT_AM'].apply(\n",
    "                lambda x: np.nan if str(x) == 'nan' else datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S').year)\n",
    "            df['EINGEFUEGT_AM_MONTH'] = df['EINGEFUEGT_AM'].apply(\n",
    "                lambda x: np.nan if str(x) == 'nan' else datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S').month)\n",
    "\n",
    "            if col not in cols_drop:\n",
    "                cols_drop.append(col)\n",
    "\n",
    "        else:\n",
    "            # drop columns have too many categorical values\n",
    "            n_unique = df[col].dropna().nunique()\n",
    "            if n_unique > 20:\n",
    "                if col not in cols_drop:\n",
    "                    cols_drop.append(col)\n",
    "\n",
    "    df.drop(columns=cols_drop, inplace=True)\n",
    "\n",
    "    return df, cols_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9264/3416488663.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_categorical_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df, drop_categorical_cols = clean_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "    DATABASE: data/df_clean.pkl\n"
     ]
    }
   ],
   "source": [
    "# # save the cleaned data as pickle file\n",
    "# database_filepath = 'data/df_clean.pkl'\n",
    "# print('Saving data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "# df.to_pickle(database_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save columns to drop to reload later\n",
    "# drop_cols += drop_categorical_cols\n",
    "# with open(cols_drop_filepath, 'wb') as f:\n",
    "#     pickle.dump(drop_cols, f)\n",
    "# print(f'Saved the list of {len(drop_cols)} columns to drop to data/drop_cols.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
